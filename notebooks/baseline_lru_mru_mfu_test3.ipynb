{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "execfile(\"../script/utils.py\")\n",
    "eventsPath = os.environ[\"YAHOO_DATA\"]\n",
    "splitedRdd = sc.textFile(eventsPath + \"/splitedData\")\n",
    "splitedRdd = splitedRdd.map(parseContextData2)\n",
    "#splitedRdd = sc.parallelize(splitedRdd.take(10000))\n",
    "splitedRddSample1 = sc.parallelize(splitedRdd.takeSample(True, 10000,0))\n",
    "splitedRddSample2 = sc.parallelize(splitedRdd.takeSample(True, 10000,1))\n",
    "splitedRddSample1.take(1)\n",
    "#(uid,[[train],[test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRecList = 5\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "def topFiveSortedList(oldList, context, probability):\n",
    "    context_oldList = [x[0] for x in oldList]\n",
    "    if context not in context_oldList:\n",
    "        for x in range(0,len(oldList)-1):\n",
    "            if x == 0 and oldList[x][1] < probability:\n",
    "                oldList[x] = (context,probability)\n",
    "                if oldList[x+1][1] < oldList[x][1]:\n",
    "                    temp = oldList[x+1] \n",
    "                    oldList[x+1] = oldList[x]\n",
    "                    oldList[x] = temp \n",
    "                else:\n",
    "                    break\n",
    "            elif oldList[x+1][1] < oldList[x][1]:\n",
    "                temp = oldList[x+1] \n",
    "                oldList[x+1] = oldList[x]\n",
    "                oldList[x] = temp \n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        index = context_oldList.index(context)\n",
    "        if oldList[index][1] < probability:\n",
    "            oldList[index] = (context,probability)\n",
    "        oldList = sorted(oldList,key=lambda x: x[1])\n",
    "    return oldList     \n",
    "def evaluation_rr(testList, recList):\n",
    "    scores = 0\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                scores = scores + 1.0 / (i+1)\n",
    "                break\n",
    "    if len(testList) != 0 :\n",
    "        scores = scores / len(testList)\n",
    "    return scores\n",
    "def evaluation_rr1(testItem, recList):\n",
    "    scores = 0\n",
    "    for i in range(len(recList)):\n",
    "        if testItem == recList[i]:\n",
    "            scores = 1.0 / (i+1)\n",
    "            break\n",
    "    return scores\n",
    "def evaluation_ap(testList, recList):\n",
    "    scores = 0\n",
    "    num = 0 \n",
    "    rr = []\n",
    "    rr[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                rr[i] = 1\n",
    "    \n",
    "    for t in testList:    \n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                for j in range(i,len(recList)):    \n",
    "                    if rr[j] == 1:\n",
    "                        scores = scores + 1.0 / (j+1)\n",
    "                        num = num + 1\n",
    "                break\n",
    "    if num == 0:\n",
    "        scores = 0\n",
    "    else:\n",
    "        scores = scores / num\n",
    "    return scores\n",
    "\n",
    "def evaluation_rap(testList,recList):\n",
    "    scores = 0.0\n",
    "    hitNum = 0  \n",
    "    for i in range(len(recList)):\n",
    "        if recList[i] in testList:\n",
    "            hitNum = hitNum + 1\n",
    "            scores = scores + 1.0*hitNum/(i+1)\n",
    "    if hitNum != 0:\n",
    "        scores = scores/hitNum\n",
    "    else:\n",
    "        scores = 0\n",
    "    return scores\n",
    "\n",
    "def evaluation_recall(testList, recList):\n",
    "    scores = 0\n",
    "    num = 0\n",
    "    recall = []\n",
    "    recall[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    rr=[]\n",
    "    rr[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                rr[i] = 1\n",
    "    for t in testList:    \n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                for j in range(i,len(recList)):    \n",
    "                    recall[j] = recall[j] + 1.0\n",
    "                    num = num + 1  \n",
    "                break    \n",
    "    recall = [0 if len(testList) == 0 else x/len(testList) for x in recall]\n",
    "    return recall\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "\n",
    "def evaluation_precision(testItem, recList):\n",
    "    scores = 0\n",
    "    if testItem in recList:\n",
    "        scores = 1.0\n",
    "    return scores  \n",
    "\n",
    "def print_result(finalScore, algorithm_name):\n",
    "    f = open('result/resultOfEvaluation2.txt','a')\n",
    "    f.write('2000 users with duplicated evaluations')\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr:'+str(finalScore.map(lambda x:x[0]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by map:'+str(finalScore.map(lambda x:x[1]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by recall:')\n",
    "    for i in range(numRecList):\n",
    "        if i == 0:\n",
    "            f.write(' '+str(finalScore.map(lambda x:x[2][i]).mean()))\n",
    "        elif i == numRecList-1:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[2][i]).mean()) + '\\n')\n",
    "        else:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[2][i]).mean()))\n",
    "    f.close()\n",
    "    \n",
    "def print_result2(finalScore, algorithm_name):\n",
    "    f = open('result/resultOfEvaluation2.txt','a')\n",
    "    f.write('2000 users with duplicated evaluations')\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr:'+str(finalScore.map(lambda x:x[0]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by map:'+str(finalScore.map(lambda x:x[1]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by recall:')\n",
    "    for i in range(numRecList):\n",
    "        if i == 0:\n",
    "            f.write(' '+str(finalScore.map(lambda x:x[2][i]).mean()))\n",
    "        elif i == numRecList-1:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[2][i]).mean()) + '\\n')\n",
    "        else:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[2][i]).mean()))\n",
    "            \n",
    "    f.write(algorithm_name + ' by precision:'+str(finalScore.map(lambda x:x[3]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by rap:'+str(finalScore.map(lambda x:x[4]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "def print_result3(finalScore, algorithm_name):\n",
    "    f = open('result/mfu_test_result1.txt','a')\n",
    "    f.write('2000 users with duplicated evaluations')\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr:'+str(finalScore.map(lambda x:x[0]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr1:'+str(finalScore.map(lambda x:x[1]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by map:'+str(finalScore.map(lambda x:x[2]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by recall:')\n",
    "    for i in range(numRecList):\n",
    "        if i == 0:\n",
    "            f.write(' '+str(finalScore.map(lambda x:x[3][i]).mean()))\n",
    "        elif i == numRecList-1:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[3][i]).mean()) + '\\n')\n",
    "        else:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[3][i]).mean()))\n",
    "            \n",
    "    f.write(algorithm_name + ' by precision:'+str(finalScore.map(lambda x:x[4]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by rap:'+str(finalScore.map(lambda x:x[5]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "def print_result4(finalScore, algorithm_name):\n",
    "    f = open('result/mfu_test_result2.txt','a')\n",
    "    f.write('10000 users with duplicated evaluations with pop apps removed')\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr:'+str(finalScore.map(lambda x:x[0]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr1:'+str(finalScore.map(lambda x:x[1]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by map:'+str(finalScore.map(lambda x:x[2]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by recall:')\n",
    "    for i in range(numRecList):\n",
    "        if i == 0:\n",
    "            f.write(' '+str(finalScore.map(lambda x:x[3][i]).mean()))\n",
    "        elif i == numRecList-1:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[3][i]).mean()) + '\\n')\n",
    "        else:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[3][i]).mean()))\n",
    "            \n",
    "    f.write(algorithm_name + ' by precision:'+str(finalScore.map(lambda x:x[4]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by rap:'+str(finalScore.map(lambda x:x[5]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def mfuFunction_P(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_precision = 0.0\n",
    "    \n",
    "    for i in range(numTest):  \n",
    "        #testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "        Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "        Recommender =  [t[0] for t in Recommender] \n",
    "\n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_precision = scores_precision / numTest\n",
    "\n",
    "    return scores_precision\n",
    "finalScore = splitedRdd.map(mfuFunction_P)\n",
    "print_result1(finalScore,'mfuFunction_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "numRecList = 5\n",
    "def lruFunction_P(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_precision = 0.0\n",
    "    for i in range(numTest):\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]), reverse=True);  #sort by timestamp with descending\n",
    "        testList_items = [t[0] for t in testList]                      #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "\n",
    "        if len(Recommender) > numRecList-1:\n",
    "            finalRecommender = Recommender[:numRecList]\n",
    "        else:    \n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "\n",
    "        scores_precision = evaluation_precision(testList_items[0], finalRecommender) + scores_precision\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]));\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_precision = scores_precision / numTest\n",
    "\n",
    "    return scores_precision\n",
    "\n",
    "finalScore = splitedRdd.map(lruFunction_P)\n",
    "#finalScore.map(lambda x:x[2][0]).mean()\n",
    "#finalScore.take(10)#,finalScore.map(lambda x:x[2]).mean()\n",
    "print_result1(finalScore, 'lruFunction_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mruFunction_P(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_precision = 0.0\n",
    "    for i in range(numTest):  \n",
    "        testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "\n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        scores_precision = evaluation_precision(testList_items[0], finalRecommender) + scores_precision\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_precision = scores_precision / numTest\n",
    "\n",
    "    return scores_precision\n",
    "\n",
    "finalScore = splitedRdd.map(mruFunction_P)\n",
    "print_result1(finalScore,'mruFunction_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2286"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numberOfApps(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    numApps = len(remove_duplicates([x[0] for x in trainList]))\n",
    "    \n",
    "    #numTrain = len(trainList)\n",
    "    return line[0],line[1],numApps\n",
    "splitedRDDFilter2 = splitedRdd.map(numberOfApps).filter(lambda x:x[2]<20).map(lambda x:(x[0],x[1]))\n",
    "#splitedRDDFilter2 = splitedRddv2.map(numberOfApps)\n",
    "splitedRDDFilter2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "numRecList = 5\n",
    "def lruFunction(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_precision = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for i in range(numTest):\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]), reverse=True);  #sort by timestamp with descending\n",
    "        testList_items = [t[0] for t in testList]                      #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "\n",
    "        if len(Recommender) > numRecList-1:\n",
    "            finalRecommender = Recommender[:numRecList]\n",
    "        else:    \n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]));\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "\n",
    "finalScore = splitedRdd.map(lruFunction)\n",
    "#finalScore.map(lambda x:x[2][0]).mean()\n",
    "#finalScore.take(10)#,finalScore.map(lambda x:x[2]).mean()\n",
    "print_result2(finalScore, 'lru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "numRecList = 5\n",
    "def lruFunction_filter(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_precision = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for i in range(numTest):\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]), reverse=True);  #sort by timestamp with descending\n",
    "        testList_items = [t[0] for t in testList]                      #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "\n",
    "        if len(Recommender) > numRecList-1:\n",
    "            finalRecommender = Recommender[:numRecList]\n",
    "        else:    \n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]));\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)   \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_rr1 = scores_rr1 / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "\n",
    "finalScore = splitedRDDFilter2.map(lruFunction_filter)\n",
    "#finalScore.map(lambda x:x[2][0]).mean()\n",
    "#finalScore.take(10)#,finalScore.map(lambda x:x[2]).mean()\n",
    "print_result3(finalScore, 'lruFunction_filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mruFunction(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_rr = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for i in range(numTest):  \n",
    "        testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "\n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "        \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "\n",
    "    return scores_rr, scores_ap, scores_recall\n",
    "finalScore = splitedRdd.map(mruFunction)\n",
    "print_result(finalScore,'mru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def mfuFunction(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for i in range(numTest):  \n",
    "        testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "        Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "        Recommender =  [t[0] for t in Recommender] \n",
    "\n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        \n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_rr1 = scores_rr1 / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "finalScore = splitedRdd.map(mfuFunction)\n",
    "print_result3(finalScore,'mfu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def mfuFunction_no_iterative(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "    RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "    #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "    Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "    Recommender =  [t[0] for t in Recommender] \n",
    "\n",
    "    if len(Recommender) > 4:\n",
    "        finalRecommender = Recommender[:5]\n",
    "    else:\n",
    "        finalRecommender = [-1,-1,-1,-1,-1]\n",
    "        numRec = len(Recommender)\n",
    "        finalRecommender[:numRec] = Recommender\n",
    "    scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "    scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "    scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "    scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "    scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "    scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "finalScore = splitedRdd.map(mfuFunction_no_iterative)\n",
    "print_result3(finalScore,'mfuFunction_no_iterative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation_rap(testList,recList):\n",
    "    scores = 0.0\n",
    "    hitNum = 0  \n",
    "    for i in range(len(recList)):\n",
    "        if recList[i] in testList:\n",
    "            hitNum = hitNum + 1\n",
    "            scores = scores + 1.0*hitNum/(i+1)\n",
    "    if hitNum != 0:\n",
    "        scores = scores/hitNum\n",
    "    else:\n",
    "        scores = 0\n",
    "    return scores\n",
    "\n",
    "a = [2,3,4,5,1]\n",
    "b = [1,22,3,14,15]\n",
    "evaluation_rap(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def mfuFunction_time(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    #trainList = trainList[(numTrain*39/40):numTrain]\n",
    "#     trainList.extend(testList[:(numTest/2)])\n",
    "#     numTrain = len(trainList)\n",
    "#     testList = testList[(numTest/2):]\n",
    "#     numTest = len(testList)\n",
    "    trainList.extend(testList)\n",
    "    numTrain = len(trainList)\n",
    "    testList = [x for x in trainList if trainList[numTrain-1][1][0] - x[1][0]<=43200]\n",
    "    numTest = len(testList)\n",
    "    trainList = trainList[:(numTrain-numTest)]\n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for i in range(numTest):  \n",
    "        while (len(trainList)>0 and testList[0][1][0]-trainList[0][1][0]>86400):\n",
    "            trainList.pop(0)\n",
    "        testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "        Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "        Recommender =  [t[0] for t in Recommender] \n",
    "\n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        \n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        \n",
    "        trainList.append(testList[0])\n",
    "        #trainList.pop(0)\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "finalScore = splitedRdd.map(mfuFunction_time)\n",
    "print_result2(finalScore,'mfuFunction_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from collections import Counter\n",
    "f = open('result/mfu_test_result1.txt','a')\n",
    "f.write('-------mfu giving weight-----')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "def mfuFunction(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for i in range(numTest):  \n",
    "        testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "        Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "#        testcount = Counter(testList_items).most_common()\n",
    "        \n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]), reverse=True);  #sort by timestamp with descending\n",
    "        RecommenderDuplicate1 =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender1 = remove_duplicates(RecommenderDuplicate1)    #remove duplicate\n",
    "        Recommender = [[t[0],t[1]*5] if t[0] in Recommender1[:10] else t for t in Recommender]\n",
    "#         Recommender = [[t[0],1.0*t[1]/numTrain] for t in Recommender]\n",
    "#         testcount = [[t[0],1.0*t[1]/numTest] for t in testcount]\n",
    "       \n",
    "    #weighted\n",
    "#         Recommender =  [[t,0] for t in Recommender] \n",
    "#         for i in range(len(Recommender)):\n",
    "#             for j in range(len(trainList)):\n",
    "#                 if trainList[j][0] == Recommender[i][0]:\n",
    "#                     if len(trainList)>0 and (trainList[-1][1][0] - trainList[j][1][0]) == 0:\n",
    "#                         weight = 1\n",
    "#                     elif len(trainList)>0:\n",
    "#                         weight = (trainList[-1][1][0] - trainList[j][1][0])/86400\n",
    "#                     else:\n",
    "#                         weight = 0\n",
    "#                     if weight != 0:\n",
    "#                         Recommender[i][1] = Recommender[i][1] + 1.0/weight\n",
    "        Recommender = sorted(Recommender,key=lambda x:-x[1])\n",
    "        Recommender =  [t[0] for t in Recommender] \n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0])); ####\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_rr1 = scores_rr1 / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "    #return Recommender[:10],numTrain,testcount,numTest\n",
    "\n",
    "finalScore = splitedRdd.map(mfuFunction)\n",
    "#finalScore.take(5)\n",
    "print_result3(finalScore,'mfu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7652,\n",
       "  [[train(itemId=79314, context=context(ts=1420997495, city=2054, lat=39.928886, lon=-75.322601, moving=2, location=2, time_of_day=3)),\n",
       "    train(itemId=57365, context=context(ts=1420998086, city=2054, lat=39.928864, lon=-75.322571, moving=1, location=2, time_of_day=3)),\n",
       "    train(itemId=57365, context=context(ts=1420998769, city=2054, lat=39.928928, lon=-75.322525, moving=1, location=2, time_of_day=3)),\n",
       "    train(itemId=2766, context=context(ts=1421006011, city=2054, lat=39.92889, lon=-75.322609, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=8509, context=context(ts=1421012576, city=2054, lat=39.928871, lon=-75.322525, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=15939, context=context(ts=1421021887, city=2054, lat=39.928848, lon=-75.322563, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=15939, context=context(ts=1421022391, city=2054, lat=39.929054, lon=-75.322777, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=77050, context=context(ts=1421022563, city=2054, lat=39.927105, lon=-75.328636, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=35168, context=context(ts=1421022981, city=7961, lat=39.903152, lon=-75.36869, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421023399, city=6161, lat=39.868038, lon=-75.392471, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421023425, city=10612, lat=39.865055, lon=-75.401009, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421023446, city=10612, lat=39.865055, lon=-75.401009, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=35168, context=context(ts=1421023463, city=10612, lat=39.865055, lon=-75.401009, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=55396, context=context(ts=1421025390, city=10612, lat=39.883511, lon=-75.431007, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=2766, context=context(ts=1421025591, city=10612, lat=39.883736, lon=-75.430908, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421025621, city=10612, lat=39.883659, lon=-75.430962, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=35168, context=context(ts=1421025635, city=10612, lat=39.883659, lon=-75.430962, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=44053, context=context(ts=1421025796, city=10612, lat=39.883633, lon=-75.43116, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=65720, context=context(ts=1421032594, city=2054, lat=39.928894, lon=-75.322609, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=44224, context=context(ts=1421032641, city=2054, lat=39.928883, lon=-75.322617, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=44053, context=context(ts=1421032672, city=2054, lat=39.928883, lon=-75.322617, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=83022, context=context(ts=1421036962, city=2054, lat=39.92889, lon=-75.322609, moving=2, location=3, time_of_day=1)),\n",
       "    train(itemId=44053, context=context(ts=1421038987, city=2054, lat=39.928917, lon=-75.32267, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=1137, context=context(ts=1421039020, city=2054, lat=39.928932, lon=-75.322617, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=79463, context=context(ts=1421039030, city=2054, lat=39.928932, lon=-75.322617, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=17663, context=context(ts=1421039098, city=2054, lat=39.928925, lon=-75.322647, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=21368, context=context(ts=1421040441, city=2054, lat=39.928925, lon=-75.322639, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=21368, context=context(ts=1421041118, city=2054, lat=39.928864, lon=-75.322609, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=21368, context=context(ts=1421041245, city=2054, lat=39.928909, lon=-75.322655, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=1137, context=context(ts=1421041478, city=2054, lat=39.928867, lon=-75.322571, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=21368, context=context(ts=1421041553, city=2054, lat=39.928856, lon=-75.322594, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=83022, context=context(ts=1421070472, city=2054, lat=39.928875, lon=-75.322647, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=79314, context=context(ts=1421071339, city=2054, lat=39.928894, lon=-75.322571, moving=1, location=2, time_of_day=2)),\n",
       "    train(itemId=35168, context=context(ts=1421071361, city=2054, lat=39.928894, lon=-75.322571, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=35168, context=context(ts=1421083028, city=3376, lat=39.921028, lon=-75.170113, moving=1, location=2, time_of_day=3)),\n",
       "    train(itemId=1137, context=context(ts=1421084312, city=3376, lat=39.921001, lon=-75.169754, moving=1, location=2, time_of_day=3)),\n",
       "    train(itemId=1137, context=context(ts=1421091109, city=3376, lat=39.920639, lon=-75.16925, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=96668, context=context(ts=1421091329, city=3376, lat=39.920414, lon=-75.169228, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=1137, context=context(ts=1421095673, city=3376, lat=39.921082, lon=-75.169815, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=65720, context=context(ts=1421096530, city=3376, lat=39.921009, lon=-75.169678, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=44224, context=context(ts=1421096538, city=3376, lat=39.921009, lon=-75.169678, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=79463, context=context(ts=1421097960, city=3376, lat=39.921028, lon=-75.169685, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=96547, context=context(ts=1421097965, city=3376, lat=39.921028, lon=-75.169685, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=47315, context=context(ts=1421102466, city=3376, lat=39.921001, lon=-75.169838, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=47315, context=context(ts=1421102627, city=3376, lat=39.920998, lon=-75.169853, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=1137, context=context(ts=1421106741, city=3376, lat=39.921024, lon=-75.169754, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=96547, context=context(ts=1421113702, city=2054, lat=39.92889, lon=-75.322609, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=1137, context=context(ts=1421119302, city=10801, lat=40.064247, lon=-75.322891, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=46117, context=context(ts=1421124723, city=12759, lat=40.118328, lon=-75.328415, moving=2, location=3, time_of_day=1)),\n",
       "    train(itemId=17663, context=context(ts=1421124730, city=12759, lat=40.118328, lon=-75.328415, moving=2, location=3, time_of_day=1)),\n",
       "    train(itemId=17663, context=context(ts=1421124731, city=12759, lat=40.118328, lon=-75.328415, moving=2, location=3, time_of_day=1)),\n",
       "    train(itemId=1137, context=context(ts=1421125791, city=12759, lat=40.1213, lon=-75.345657, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=65720, context=context(ts=1421128025, city=2054, lat=39.92889, lon=-75.322609, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=44224, context=context(ts=1421128082, city=2054, lat=39.92889, lon=-75.322609, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=79314, context=context(ts=1421157706, city=2054, lat=39.928894, lon=-75.322639, moving=1, location=2, time_of_day=2)),\n",
       "    train(itemId=47315, context=context(ts=1421166001, city=3376, lat=39.920998, lon=-75.169846, moving=1, location=2, time_of_day=3)),\n",
       "    train(itemId=79314, context=context(ts=1421172088, city=3376, lat=39.921005, lon=-75.169769, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=47315, context=context(ts=1421172089, city=3376, lat=39.921005, lon=-75.169769, moving=1, location=3, time_of_day=3)),\n",
       "    train(itemId=65720, context=context(ts=1421174283, city=3376, lat=39.920696, lon=-75.169716, moving=1, location=3, time_of_day=3)),\n",
       "    train(itemId=44224, context=context(ts=1421174295, city=3376, lat=39.920696, lon=-75.169716, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=47315, context=context(ts=1421174511, city=3376, lat=39.920998, lon=-75.169762, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=44224, context=context(ts=1421178986, city=3376, lat=39.921017, lon=-75.169777, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=47315, context=context(ts=1421178992, city=3376, lat=39.921017, lon=-75.169777, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=55396, context=context(ts=1421182371, city=3376, lat=39.921268, lon=-75.170021, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=55396, context=context(ts=1421182685, city=3376, lat=39.921329, lon=-75.169754, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=79463, context=context(ts=1421184147, city=3376, lat=39.921318, lon=-75.169685, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=79463, context=context(ts=1421185480, city=3376, lat=39.921047, lon=-75.169777, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=55396, context=context(ts=1421188421, city=3376, lat=39.921364, lon=-75.169685, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=79463, context=context(ts=1421188422, city=3376, lat=39.921364, lon=-75.169685, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=98259, context=context(ts=1421192386, city=3376, lat=39.921021, lon=-75.169754, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=98259, context=context(ts=1421192910, city=3376, lat=39.921001, lon=-75.169746, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421193505, city=3376, lat=39.920624, lon=-75.169861, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=79463, context=context(ts=1421194113, city=3376, lat=39.918041, lon=-75.171219, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=98259, context=context(ts=1421194127, city=3376, lat=39.918041, lon=-75.171219, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421194134, city=3376, lat=39.918041, lon=-75.171219, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=98259, context=context(ts=1421195445, city=566, lat=39.92709, lon=-75.30265, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=98259, context=context(ts=1421196624, city=566, lat=39.926304, lon=-75.305603, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=65720, context=context(ts=1421210143, city=2054, lat=39.928894, lon=-75.322609, moving=2, location=3, time_of_day=1)),\n",
       "    train(itemId=44224, context=context(ts=1421210174, city=2054, lat=39.928894, lon=-75.322609, moving=2, location=3, time_of_day=1)),\n",
       "    train(itemId=79314, context=context(ts=1421243149, city=2054, lat=39.928921, lon=-75.322647, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=3492, context=context(ts=1421244075, city=2054, lat=39.928837, lon=-75.32251, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=79314, context=context(ts=1421246947, city=3376, lat=39.920975, lon=-75.169807, moving=1, location=2, time_of_day=2)),\n",
       "    train(itemId=79463, context=context(ts=1421260254, city=3376, lat=39.92115, lon=-75.169746, moving=1, location=3, time_of_day=3)),\n",
       "    train(itemId=79463, context=context(ts=1421261080, city=3376, lat=39.92065, lon=-75.169975, moving=1, location=3, time_of_day=3)),\n",
       "    train(itemId=57365, context=context(ts=1421288415, city=6518, lat=39.889526, lon=-75.311455, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=100207, context=context(ts=1421288497, city=3762, lat=39.895386, lon=-75.315224, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=100207, context=context(ts=1421288653, city=11567, lat=39.907711, lon=-75.32695, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421289088, city=2054, lat=39.920586, lon=-75.323524, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=65720, context=context(ts=1421298646, city=2054, lat=39.92897, lon=-75.322655, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=44224, context=context(ts=1421298707, city=2054, lat=39.928947, lon=-75.322617, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=98259, context=context(ts=1421301028, city=2054, lat=39.928886, lon=-75.322639, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=79314, context=context(ts=1421329695, city=2054, lat=39.928902, lon=-75.322594, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=77050, context=context(ts=1421330913, city=2054, lat=39.928879, lon=-75.322578, moving=1, location=2, time_of_day=2)),\n",
       "    train(itemId=100207, context=context(ts=1421330985, city=2054, lat=39.928879, lon=-75.322578, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=55396, context=context(ts=1421334964, city=3376, lat=39.945053, lon=-75.1754, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=83022, context=context(ts=1421346169, city=3376, lat=39.921009, lon=-75.169777, moving=1, location=3, time_of_day=3)),\n",
       "    train(itemId=100207, context=context(ts=1421346236, city=3376, lat=39.921009, lon=-75.169777, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=77050, context=context(ts=1421346261, city=3376, lat=39.92099, lon=-75.169754, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=99513, context=context(ts=1421351025, city=3376, lat=39.921703, lon=-75.169395, moving=3, location=3, time_of_day=3)),\n",
       "    train(itemId=99513, context=context(ts=1421351408, city=3376, lat=39.921703, lon=-75.169395, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=65720, context=context(ts=1421354292, city=3376, lat=39.92099, lon=-75.169716, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=99513, context=context(ts=1421379036, city=4114, lat=40.031204, lon=-75.360741, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=65720, context=context(ts=1421388469, city=2054, lat=39.928963, lon=-75.322639, moving=1, location=1, time_of_day=1)),\n",
       "    train(itemId=44224, context=context(ts=1421388485, city=2054, lat=39.928963, lon=-75.322639, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=99513, context=context(ts=1421389452, city=2054, lat=39.928932, lon=-75.322647, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=99513, context=context(ts=1421389484, city=2054, lat=39.928932, lon=-75.322647, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=99513, context=context(ts=1421389570, city=2054, lat=39.928886, lon=-75.322639, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=79314, context=context(ts=1421415965, city=2054, lat=39.928936, lon=-75.322655, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=96668, context=context(ts=1421418400, city=6518, lat=39.886261, lon=-75.308937, moving=1, location=2, time_of_day=2)),\n",
       "    train(itemId=98259, context=context(ts=1421418404, city=6518, lat=39.886261, lon=-75.308937, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=44224, context=context(ts=1421418636, city=2669, lat=39.872383, lon=-75.296165, moving=4, location=2, time_of_day=2)),\n",
       "    train(itemId=44053, context=context(ts=1421425436, city=3376, lat=39.920887, lon=-75.169876, moving=1, location=2, time_of_day=3)),\n",
       "    train(itemId=77050, context=context(ts=1421430352, city=3376, lat=39.921555, lon=-75.169662, moving=2, location=2, time_of_day=3)),\n",
       "    train(itemId=57365, context=context(ts=1421430401, city=3376, lat=39.921474, lon=-75.169724, moving=2, location=2, time_of_day=3))],\n",
       "   [train(itemId=2766, context=context(ts=1421439172, city=3376, lat=39.921001, lon=-75.169716, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=8509, context=context(ts=1421445623, city=3376, lat=39.92136, lon=-75.169205, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=18309, context=context(ts=1421448777, city=3376, lat=39.921047, lon=-75.169785, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=44224, context=context(ts=1421454174, city=11567, lat=39.906124, lon=-75.324989, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=65720, context=context(ts=1421454239, city=11567, lat=39.907658, lon=-75.326881, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421454352, city=11567, lat=39.910431, lon=-75.325493, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=83022, context=context(ts=1421458940, city=2054, lat=39.928925, lon=-75.322571, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=79463, context=context(ts=1421459449, city=2054, lat=39.92897, lon=-75.322632, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=85325, context=context(ts=1421459485, city=2054, lat=39.928932, lon=-75.322609, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=55396, context=context(ts=1421459789, city=2054, lat=39.928932, lon=-75.322609, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=25375, context=context(ts=1421464675, city=7267, lat=39.951557, lon=-75.28183, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=57365, context=context(ts=1421473153, city=2054, lat=39.928932, lon=-75.322609, moving=1, location=1, time_of_day=1)),\n",
       "    train(itemId=100207, context=context(ts=1421473184, city=2054, lat=39.928932, lon=-75.322609, moving=2, location=1, time_of_day=1)),\n",
       "    train(itemId=83022, context=context(ts=1421474982, city=2054, lat=39.928944, lon=-75.322655, moving=1, location=1, time_of_day=1)),\n",
       "    train(itemId=79314, context=context(ts=1421494532, city=2054, lat=39.928947, lon=-75.322647, moving=1, location=1, time_of_day=2)),\n",
       "    train(itemId=98259, context=context(ts=1421496753, city=7961, lat=39.910122, lon=-75.360558, moving=1, location=1, time_of_day=2)),\n",
       "    train(itemId=79314, context=context(ts=1421498903, city=2054, lat=39.920982, lon=-75.340683, moving=2, location=1, time_of_day=2)),\n",
       "    train(itemId=83022, context=context(ts=1421499275, city=2054, lat=39.920937, lon=-75.340561, moving=2, location=1, time_of_day=2)),\n",
       "    train(itemId=98259, context=context(ts=1421499359, city=2054, lat=39.920937, lon=-75.340561, moving=2, location=1, time_of_day=2)),\n",
       "    train(itemId=2766, context=context(ts=1421499648, city=2054, lat=39.920937, lon=-75.340561, moving=2, location=2, time_of_day=2)),\n",
       "    train(itemId=55396, context=context(ts=1421516199, city=9875, lat=40.014111, lon=-75.328636, moving=2, location=2, time_of_day=3)),\n",
       "    train(itemId=15939, context=context(ts=1421516230, city=9875, lat=40.014111, lon=-75.328636, moving=2, location=2, time_of_day=3)),\n",
       "    train(itemId=98259, context=context(ts=1421516307, city=9875, lat=40.014111, lon=-75.328636, moving=2, location=2, time_of_day=3)),\n",
       "    train(itemId=98259, context=context(ts=1421520540, city=11625, lat=39.994122, lon=-75.299866, moving=1, location=3, time_of_day=3)),\n",
       "    train(itemId=65720, context=context(ts=1421521554, city=11625, lat=39.968479, lon=-75.295067, moving=2, location=3, time_of_day=3)),\n",
       "    train(itemId=44224, context=context(ts=1421521563, city=11625, lat=39.969086, lon=-75.297234, moving=4, location=3, time_of_day=3)),\n",
       "    train(itemId=55396, context=context(ts=1421529130, city=2540, lat=39.898556, lon=-75.408752, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=55396, context=context(ts=1421529372, city=2540, lat=39.917, lon=-75.420219, moving=4, location=3, time_of_day=4)),\n",
       "    train(itemId=57917, context=context(ts=1421530643, city=2540, lat=39.915691, lon=-75.432289, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=79463, context=context(ts=1421533311, city=2540, lat=39.915653, lon=-75.432228, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=55396, context=context(ts=1421534088, city=2540, lat=39.915653, lon=-75.432228, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=55396, context=context(ts=1421534164, city=2540, lat=39.915649, lon=-75.432526, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=98259, context=context(ts=1421534509, city=2540, lat=39.915833, lon=-75.432358, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=98259, context=context(ts=1421534734, city=2540, lat=39.915836, lon=-75.432274, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=81109, context=context(ts=1421541052, city=2540, lat=39.915546, lon=-75.433136, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=98259, context=context(ts=1421547846, city=5038, lat=39.947487, lon=-75.505997, moving=1, location=3, time_of_day=4)),\n",
       "    train(itemId=65720, context=context(ts=1421551891, city=5038, lat=39.947487, lon=-75.505997, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=44224, context=context(ts=1421552037, city=5038, lat=39.947491, lon=-75.505997, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=8509, context=context(ts=1421552203, city=5038, lat=39.947487, lon=-75.505997, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=44053, context=context(ts=1421552275, city=5038, lat=39.947487, lon=-75.505997, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=8509, context=context(ts=1421552297, city=5038, lat=39.947487, lon=-75.505997, moving=2, location=3, time_of_day=4)),\n",
       "    train(itemId=96668, context=context(ts=1421559548, city=2054, lat=39.928883, lon=-75.322556, moving=1, location=1, time_of_day=1)),\n",
       "    train(itemId=98259, context=context(ts=1421559911, city=2054, lat=39.928909, lon=-75.322639, moving=1, location=1, time_of_day=1))]])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "from collections import Counter\n",
    "def removePopApps(line):\n",
    "    listGroup = line[1]\n",
    "    top = [t[0] for t in Counter([t[0] for t in listGroup[0]]  + [t[0] for t in listGroup[1]] ).most_common()][:15]  #top5\n",
    "    \n",
    "    listGroup[0] = [t for t in listGroup[0] if t[0] not in top]      #0.8 train set\n",
    "    listGroup[1] = [t for t in listGroup[1] if t[0] not in top]       #0.2 test set\n",
    "    return line[0],listGroup\n",
    "\n",
    "splitedRdd1 = splitedRddSample1.map(removePopApps)\n",
    "splitedRdd2 = splitedRddSample2.map(removePopApps)\n",
    "splitedRdd2.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from collections import Counter\n",
    "f = open('result/mfu_test_result2.txt','a')\n",
    "f.write('-------mfu only recommend to 5 test-----')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "def mfuFunction(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    \n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "#     top = [t[0] for t in Counter([t[0] for t in listGroup[0]]  + [t[0] for t in listGroup[1]] ).most_common()][:5]  #top5\n",
    "    \n",
    "    trainList = [t for t in listGroup[0]]      #0.8 train set\n",
    "    testList = [t for t in listGroup[1]]       #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    \n",
    "    for i in range(numTest):  \n",
    "        testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "        Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "#        testcount = Counter(testList_items).most_common()\n",
    "        \n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]), reverse=True);  #sort by timestamp with descending\n",
    "        RecommenderDuplicate1 =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender1 = remove_duplicates(RecommenderDuplicate1)    #remove duplicate\n",
    "        Recommender = [[t[0],t[1]*5] if t[0] in Recommender1[:10] else t for t in Recommender]\n",
    "#         Recommender = [[t[0],1.0*t[1]/numTrain] for t in Recommender]\n",
    "#         testcount = [[t[0],1.0*t[1]/numTest] for t in testcount]\n",
    "       \n",
    "    #weighted\n",
    "#         Recommender =  [[t,0] for t in Recommender] \n",
    "#         for i in range(len(Recommender)):\n",
    "#             for j in range(len(trainList)):\n",
    "#                 if trainList[j][0] == Recommender[i][0]:\n",
    "#                     if len(trainList)>0 and (trainList[-1][1][0] - trainList[j][1][0]) == 0:\n",
    "#                         weight = 1\n",
    "#                     elif len(trainList)>0:\n",
    "#                         weight = (trainList[-1][1][0] - trainList[j][1][0])/86400\n",
    "#                     else:\n",
    "#                         weight = 0\n",
    "#                     if weight != 0:\n",
    "#                         Recommender[i][1] = Recommender[i][1] + 1.0/weight\n",
    "        Recommender = sorted(Recommender,key=lambda x:-x[1])\n",
    "        Recommender =  [t[0] for t in Recommender] \n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        if len(testList_items)>5:\n",
    "            testList_items = testList_items[:5]\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0])); ####\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_rr1 = scores_rr1 / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "    #return Recommender[:10],numTrain,testcount,numTest\n",
    "\n",
    "finalScore = splitedRddSample1.map(mfuFunction)\n",
    "print_result4(finalScore,'mfu_sample1')\n",
    "finalScore = splitedRddSample2.map(mfuFunction)\n",
    "#finalScore.take(5)\n",
    "print_result4(finalScore,'mfu_sample2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splitedRddSample1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8585e20661c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores_rr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores_rr1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_ap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_recall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_precision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_rap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;31m#    return line[2][1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mfinalScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitedRddSample1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbayesian_moving\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[0mprint_result4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalScore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bayesian_moving_sample1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0mfinalScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitedRddSample2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbayesian_moving\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'splitedRddSample1' is not defined"
     ]
    }
   ],
   "source": [
    "f = open('result/mfu_test_result2.txt','a')\n",
    "f.write('-------bayesian_moving only recommend to 5-----')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "def bayesian_moving(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    trainList = listGroup[0]      #0.8 train set\n",
    "    testList = listGroup[1]       #0.2 test set\n",
    "    trainList = [(t[0],t[1][4]) for t in trainList] #itemId,movingId\n",
    "    testList = [(t[0],t[1][4]) for t in testList]   #itemId,movingID\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    \n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_precision = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for i in range(numTest):\n",
    "        context = [x for x in trainList if x[1]==testList[0][1]]\n",
    "        numContext = float(len(context))\n",
    "        if numTrain != 0:\n",
    "            p_context = numContext # /numTrain  #P(C1i, C2j, C3k)\n",
    "        else:\n",
    "            p_context = 0\n",
    "        p_app = [(-1,0),(-1,0),(-1,0),(-1,0),(-1,0)]\n",
    "        context_no_duplicate = remove_duplicates(context)\n",
    "        for c in context_no_duplicate:\n",
    "            appi = [x for x in trainList if x[0]==c[0]]\n",
    "            numAppi = float(len(appi))\n",
    "            if numTrain != 0:\n",
    "                p_appi = numAppi   #/numTrain\n",
    "            else:\n",
    "                p_appi = 0\n",
    "            contextAppi = [x for x in trainList if x[0]==c[0] and x[1]==c[1]]\n",
    "            if numAppi != 0:    #P(C1i, C2j, C3k | APPid)\n",
    "                p_contextAppi = len(contextAppi)/numAppi \n",
    "            else:\n",
    "                p_contextAppi = 0\n",
    "            if p_context != 0:  #P(APPid | C1i,C2j,C3k = P(C1i, C2j, C3k | APPid)  P(APPid) /P(C1i, C2j, C3k)\n",
    "                p = p_contextAppi * p_appi / p_context\n",
    "            else:\n",
    "                p = 0\n",
    "            p_app = topFiveSortedList(p_app,c[0],p)\n",
    "        p_app = sorted(p_app,key=lambda x: -x[1])\n",
    "        testList_items = [t[0] for t in testList]                      #take only id for test set\n",
    "        finalRecommender =  map(lambda x:x[0],p_app[:5])        #take only id for train set\n",
    "        \n",
    "        if len(testList_items)>5:\n",
    "            testList_items = testList_items[:5]\n",
    "        \n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(lambda x,y :x+y, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        \n",
    "        trainList.append(testList[0])\n",
    "        \n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_rr1 = scores_rr1 / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr,scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "#    return line[2][1]\n",
    "finalScore = splitedRddSample1.map(bayesian_moving)\n",
    "print_result4(finalScore, 'bayesian_moving_sample1')\n",
    "finalScore = splitedRddSample2.map(bayesian_moving)\n",
    "print_result4(finalScore, 'bayesian_moving_sample2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
