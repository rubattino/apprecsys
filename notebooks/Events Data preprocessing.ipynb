{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'001e6d8e-cbe7-4374-8c38-f37962a457e9\\tair.com.smashatom.bingo\\t1421009506\\t47.237476\\t-122.530884\\tTacoma\\t6\\t12\\tApp_Opened',\n",
       " u'001e6d8e-cbe7-4374-8c38-f37962a457e9\\tcom.android.vending\\t1421029924\\t47.237476\\t-122.530891\\tTacoma\\t6\\t18\\tApp_Opened',\n",
       " u'001e6d8e-cbe7-4374-8c38-f37962a457e9\\tair.com.buffalo_studios.bingorush2\\t1421015988\\t47.237461\\t-122.530899\\tTacoma\\t6\\t14\\tApp_Opened']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventsPath = os.environ[\"YAHOO_DATA\"]\n",
    "rawEventsRdd = sc.textFile(eventsPath + \"events.txt\")\n",
    "rawEventsRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawAppListRdd = sc.textFile(eventsPath + \"userapplist.txt\")\n",
    "rawAppListRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "EventDataRow = namedtuple(\"EventDataRow\", [\"userId\", \"itemId\", \"ts\", \"latitude\", \"longitude\", \"city\", \"day_of_week\", \"time_of_day\" , \"event_type\"])\n",
    "\n",
    "def parseRawData(line):\n",
    "    lineSplit = line.split(\"\\t\")\n",
    "    return EventDataRow(userId=lineSplit[0],\n",
    "                      itemId=lineSplit[1],\n",
    "                      ts=int(lineSplit[2]),\n",
    "                      latitude=float(lineSplit[3]),\n",
    "                      longitude=float(lineSplit[4]),\n",
    "                      city=lineSplit[5],\n",
    "                      day_of_week=int(lineSplit[6]),\n",
    "                      time_of_day=int(lineSplit[7]),\n",
    "                      event_type=lineSplit[-1],\n",
    "    )\n",
    "    \n",
    "\n",
    "eventsRdd = rawEventsRdd.map(parseRawData).cache()\n",
    "eventsRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventsRdd.filter(lambda x: x.city==\"\" ).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userIdConversionDictionary = eventsRdd.map(lambda x: x.userId).distinct().zipWithIndex().collectAsMap()\n",
    "userIdConversionDictionaryBroadcast = sc.broadcast(userIdConversionDictionary)\n",
    "itemIdConversionDictionary = eventsRdd.map(lambda x: x.itemId).distinct().zipWithIndex().collectAsMap()\n",
    "itemIdConversionDictionaryBroadcast = sc.broadcast(itemIdConversionDictionary)\n",
    "cityConversionDictionary = eventsRdd.map(lambda x: x.city).distinct().zipWithIndex().collectAsMap()\n",
    "cityConversionDictionaryBroadcast = sc.broadcast(cityConversionDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventsConvertedRdd = eventsRdd.map(lambda x: EventDataRow(\n",
    "    userId=userIdConversionDictionaryBroadcast.value[x.userId],\n",
    "    itemId=itemIdConversionDictionaryBroadcast.value[x.itemId],\n",
    "    ts=x.ts,\n",
    "    latitude=x.latitude,\n",
    "    longitude=x.longitude,\n",
    "    city=cityConversionDictionaryBroadcast.value[x.city],\n",
    "    day_of_week=x.day_of_week,\n",
    "    time_of_day=x.time_of_day,\n",
    "    event_type=x.event_type\n",
    "    ))\n",
    "\n",
    "eventsConvertedRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventsConvertedRdd.filter(lambda eventRaw: eventRaw.event_type=='App_Opened').map(lambda eventRaw: (\n",
    "    eventRaw.userId,eventRaw.itemId,eventRaw.ts,eventRaw.city,eventRaw.day_of_week,eventRaw.time_of_day,\n",
    "    eventRaw.latitude,eventRaw.longitude)\n",
    "        ).saveAsTextFile(eventsPath + \"events_parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(eventsPath + 'userIdConversionDictionary.txt', 'w') as outfile:\n",
    "    json.dump(userIdConversionDictionary, outfile)\n",
    "with open(eventsPath + 'itemIdConversionDictionary.txt', 'w') as outfile:\n",
    "    json.dump(itemIdConversionDictionary, outfile)\n",
    "with open(eventsPath + 'cityConversionDictionary.txt', 'w') as outfile:\n",
    "    json.dump(cityConversionDictionary, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseUserAppList(line):\n",
    "    lineSplit = line.split(\"\\t\")\n",
    "    return userIdConversionDictionary[lineSplit[0]],[itemIdConversionDictionary[app[1:-1]] for app in lineSplit[1][1:-1].split(\",\")]\n",
    "\n",
    "appListRdd = rawAppListRdd.map(parseUserAppList)\n",
    "appListMap = appListRdd.collectAsMap()\n",
    "with open(eventsPath + '/userAppMap.txt', 'w') as outfile:\n",
    "    json.dump(appListMap, outfile)\n",
    "appListRdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data into context information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execfile(\"../script/utils.py\")\n",
    "eventRDD = loadDataset(eventsPath + \"events_parsed_subset\").groupBy(lambda x: x.userId).map(lambda (x,y): (x, sorted(list(y),key=lambda a: a.ts)))\n",
    "#eventRDD = eventRDD.map(lambda x: (x[0], \n",
    "#                        map(lambda y : TrainRow(itemId=y.itemId, \n",
    "#                                               context = ContextRow(ts=y.ts,city=y.city,\n",
    "#                                                                   lat=y.lat, lon=y.lon, moving = 1)), x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detectMovement(line):\n",
    "    #location clustering\n",
    "    listGroup = map(lambda x: list(x), line[1])\n",
    "    workGroup = [x for x in listGroup if datetime.datetime.fromtimestamp(int(x[2])).hour >= 6 and  \n",
    "            datetime.datetime.fromtimestamp(int(x[2])).hour <= 18]\n",
    "    numNearLocation = []\n",
    "    i = 0\n",
    "    for x in workGroup:\n",
    "        numNearLocation.append(0);\n",
    "        for y in workGroup:\n",
    "            if haversine(x[5], x[4], y[5], y[4]) < 0.1:\n",
    "                numNearLocation[i] = numNearLocation[i] + 1\n",
    "        i = i + 1\n",
    "    if len(numNearLocation) > 0:\n",
    "        index_work = numNearLocation.index(max(numNearLocation))\n",
    "    else:\n",
    "        index_work = -1\n",
    "    \n",
    "    homeGroup = [x for x in listGroup if datetime.datetime.fromtimestamp(int(x[2])).hour < 6 or\n",
    "            datetime.datetime.fromtimestamp(int(x[2])).hour > 18]\n",
    "    \n",
    "    numNearLocation = []\n",
    "    i = 0\n",
    "    for x in homeGroup:\n",
    "        numNearLocation.append(0);\n",
    "        for y in homeGroup:\n",
    "            if haversine(x[5], x[4], y[5], y[4]) < 0.1:\n",
    "                numNearLocation[i] = numNearLocation[i] + 1\n",
    "        i = i + 1\n",
    "    if len(numNearLocation) > 0:\n",
    "        index_home = numNearLocation.index(max(numNearLocation))\n",
    "    else:\n",
    "        index_home = -1\n",
    "\n",
    "    if index_home != -1 and index_work != -1:\n",
    "        listGroup = [(x[0],x[2],1) if haversine(x[5], x[4], workGroup[index_work][3], workGroup[index_work][2]) < 0.01\n",
    "                 else( \n",
    "                    (x[0],x[2],2) if haversine(x[5], x[4], homeGroup[index_home][3], homeGroup[index_home][2]) < 0.01\n",
    "                    else (x[0],x[2],3) \n",
    "                    )\n",
    "                 for x in listGroup]\n",
    "    else:\n",
    "        listGroup = [(x[0],x[2],3)\n",
    "                 for x in listGroup]\n",
    "    \n",
    "    \n",
    "    listGroup = [(x[0],1) if datetime.datetime.fromtimestamp(int(x[1])).hour >= 6 and\n",
    "                datetime.datetime.fromtimestamp(int(x[1])).hour <= 13\n",
    "                    else(\n",
    "                      (x[0],2) if datetime.datetime.fromtimestamp(int(x[1])).hour >= 13 and\n",
    "                        datetime.datetime.fromtimestamp(int(x[1])).hour <= 18\n",
    "                      else (x[0],3)\n",
    "                    )\n",
    "                for x in listGroup]\n",
    "    #movement\n",
    "    data = line[1]\n",
    "    newData = [(data[0][1], data[0][2], data[0][3], data[0][4],data[0][5], 1, listGroup[0][1])]\n",
    "    for i in xrange(1,len(data)):\n",
    "        event = data[i]\n",
    "        distance = haversine(event[5],event[4], data[i-1][5], data[i-1][4]) * 1000 #in meters\n",
    "        time_difference = event.ts - newData[i-1][1] #in seconds\n",
    "        moving = 1 #not available \n",
    "        if time_difference <= 300: #if 2 consecutive events are more than 300 seconds away, the movement is not available\n",
    "            velocity =  distance/time_difference if time_difference > 0 else -1\n",
    "            if velocity < 0:\n",
    "                moving = 1; #not available\n",
    "            elif velocity >= 0 and velocity <= 1:\n",
    "                moving = 2  #standing still\n",
    "            elif velocity <=2.4:\n",
    "                moving = 3 #walking spead\n",
    "            else:\n",
    "                moving = 4 #faster\n",
    "        newData.append((event[1],event[2],event[3],event[4],event[5], moving, listGroup[i][1]))\n",
    "    #return (line[0], map(lambda el : TrainRow(el[0], ContextRow._make(el[1:])),newData))\n",
    "    return (line[0], newData)\n",
    "eventRDD_context = eventRDD.map(detectMovement)\n",
    "eventRDD_context.take(1)\n",
    "#train(itemId=60075, context=context(ts=1421371713, city=12940, lat=43.503536, lon=-88.558907, moving=1, location=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splitedData = splitRddV2(eventRDD_context,0.8)\n",
    "splitedData.saveAsTextFile(eventsPath + \"splitedData\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_rdd = sc.textFile(eventsPath + \"train\")\n",
    "train_rdd = train_rdd.map(parseContextData)\n",
    "train_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_rdd = sc.textFile(eventsPath + \"test\")\n",
    "test_rdd = test_rdd.map(parseContextData)\n",
    "test_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitedRD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
