{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "rawEventsRdd = sc.textFile(\"/home/mert/yahoo/events.txt\")\n",
    "EventDataRow = namedtuple(\"EventDataRow\", [\"userId\", \"itemId\", \"ts\", \"latitude\", \"longitude\", \"city\", \"day_of_week\", \"time_of_day\" , \"event_type\"])\n",
    "def parseRawData(line):\n",
    "    lineSplit = line.split(\"\\t\")\n",
    "    return EventDataRow(userId=lineSplit[0],\n",
    "                      itemId=lineSplit[1],\n",
    "                      ts=int(lineSplit[2]),\n",
    "                      latitude=float(lineSplit[3]),\n",
    "                      longitude=float(lineSplit[4]),\n",
    "                      city=lineSplit[5],\n",
    "                      day_of_week=int(lineSplit[6]),\n",
    "                      time_of_day=int(lineSplit[7]),\n",
    "                      event_type=lineSplit[-1],\n",
    "    )\n",
    "#eventsRdd = sc.parallelize(rawEventsRdd.map(parseRawData).take(10000000))\n",
    "eventsRdd = rawEventsRdd.map(parseRawData).cache()\n",
    "userIdConversionDictionary = eventsRdd.map(lambda x: x.userId).distinct().zipWithIndex().collectAsMap()\n",
    "userIdConversionDictionaryBroadcast = sc.broadcast(userIdConversionDictionary)\n",
    "itemIdConversionDictionary = eventsRdd.map(lambda x: x.itemId).distinct().zipWithIndex().collectAsMap()\n",
    "itemIdConversionDictionaryBroadcast = sc.broadcast(itemIdConversionDictionary)\n",
    "cityConversionDictionary = eventsRdd.map(lambda x: x.city).distinct().zipWithIndex().collectAsMap()\n",
    "cityConversionDictionaryBroadcast = sc.broadcast(cityConversionDictionary)\n",
    "\n",
    "eventsConvertedRdd = eventsRdd.map(lambda x: EventDataRow(\n",
    "    userId=userIdConversionDictionaryBroadcast.value[x.userId],\n",
    "    itemId=itemIdConversionDictionaryBroadcast.value[x.itemId],\n",
    "    ts=x.ts,\n",
    "    latitude=x.latitude,\n",
    "    longitude=x.longitude,\n",
    "    city=cityConversionDictionaryBroadcast.value[x.city],\n",
    "    day_of_week=x.day_of_week,\n",
    "    time_of_day=x.time_of_day,\n",
    "    event_type=x.event_type\n",
    "    ))\n",
    "eventsConvertedRdd.take(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalRDD = eventsConvertedRdd.map(lambda x: [\n",
    "    x.userId,(\n",
    "    x.itemId,\n",
    "    x.ts,\n",
    "    x.latitude,\n",
    "    x.longitude,)\n",
    "    ])\n",
    "finalRDD.take(3)\n",
    "#groupData = map((lambda (x,y): (x, list(y))), sorted(finalRDD.groupByKey().collect()))\n",
    "#groupData = map((lambda (x,y): (x, sorted(list(y),key=lambda a: a[1]))), sorted(finalRDD.groupByKey()))\n",
    "groupData = finalRDD.groupByKey().map(lambda (x,y): (x, sorted(list(y),key=lambda a: a[1])))\n",
    "#groupData = sc.parallelize(groupData.take(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "def detectMovement(x):\n",
    "    data = x[1]\n",
    "    newData = [(data[0][0], data[0][1], data[0][2], data[0][3], 1)]\n",
    "    for i in xrange(1,len(data)):\n",
    "        event = data[i]\n",
    "        distance = haversine(event[3],event[2], data[i-1][3], data[i-1][2]) * 1000 #in meters\n",
    "        time_difference = event[1] - newData[i-1][1] #in seconds\n",
    "        moving = 1 #not available \n",
    "        if time_difference <= 300: #if 2 consecutive events are more than 300 seconds away, the movement is not available\n",
    "            velocity =  distance/time_difference if time_difference > 0 else -1\n",
    "            if velocity < 0:\n",
    "                moving = 1; #not available\n",
    "            elif velocity >= 0 and velocity <= 1:\n",
    "                moving = 2  #standing still\n",
    "            elif velocity <=2.4:\n",
    "                moving = 3 #walking spead\n",
    "            else:\n",
    "                moving = 4 #faster\n",
    "        newData.append((event[0],event[1],event[2],event[3], moving))\n",
    "    return (x[0], newData)\n",
    "    #return x\n",
    "#print haversine(elem[0][1][2][1],elem[0][1][1][1],elem[6][1][2][1],elem[6][1][1][1])\n",
    "groupData = groupData.map(detectMovement).cache()\n",
    "\n",
    "#groupData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from collections import Counter\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def convertLocation(line):\n",
    "    listGroup = line[1]\n",
    "    workGroup = [x for x in listGroup if datetime.datetime.fromtimestamp(int(x[1])).hour >= 6 and  \n",
    "            datetime.datetime.fromtimestamp(int(x[1])).hour <= 18]\n",
    "    numNearLocation = []\n",
    "    i = 0\n",
    "    for x in workGroup:\n",
    "        numNearLocation.append(0);\n",
    "        for y in workGroup:\n",
    "            if haversine(x[3], x[2], y[3], y[2]) < 0.1:\n",
    "                numNearLocation[i] = numNearLocation[i] + 1\n",
    "        i = i + 1\n",
    "    if len(numNearLocation) > 0:\n",
    "        index_work = numNearLocation.index(max(numNearLocation))\n",
    "    else:\n",
    "        index_work = -1\n",
    "#     workGroup = [(x[0],x[1],x[2],x[3],1) if haversine(x[3], x[2], workGroup[index_work][3], workGroup[index_work][2]) < 0.1 \n",
    "#                  else (x[0],x[1],x[2],x[3],0) for x in workGroup]\n",
    "    #workGroup3 = [(x[0],x[1],0)  for x in workGroup if haversine(x[3], x[2], workGroup[index][3], workGroup[index][2]) >= 0.1]        \n",
    "    \n",
    "    homeGroup = [x for x in listGroup if datetime.datetime.fromtimestamp(int(x[1])).hour < 6 or\n",
    "            datetime.datetime.fromtimestamp(int(x[1])).hour > 18]\n",
    "    \n",
    "    numNearLocation = []\n",
    "    i = 0\n",
    "    for x in homeGroup:\n",
    "        numNearLocation.append(0);\n",
    "        for y in homeGroup:\n",
    "            if haversine(x[3], x[2], y[3], y[2]) < 0.1:\n",
    "                numNearLocation[i] = numNearLocation[i] + 1\n",
    "        i = i + 1\n",
    "    if len(numNearLocation) > 0:\n",
    "        index_home = numNearLocation.index(max(numNearLocation))\n",
    "    else:\n",
    "        index_home = -1\n",
    "#     homeGroup = [(x[0],x[1],x[2],x[3],2) if haversine(x[3], x[2], homeGroup[index_home][3], homeGroup[index_home][2]) < 0.1 \n",
    "#                  else (x[0],x[1],x[2],x[3],0) for x in homeGroup]\n",
    "    \n",
    "    if index_home != -1 and index_work != -1:\n",
    "        listGroup = [(x[0],x[1],x[4],1) if haversine(x[3], x[2], workGroup[index_work][3], workGroup[index_work][2]) < 0.01\n",
    "                 else( \n",
    "                    (x[0],x[1],x[4],2) if haversine(x[3], x[2], homeGroup[index_home][3], homeGroup[index_home][2]) < 0.01\n",
    "                    else (x[0],x[1],x[4],3) \n",
    "                    )\n",
    "                 for x in listGroup]\n",
    "    else:\n",
    "        listGroup = [(x[0],x[1],x[4],3)\n",
    "                 for x in listGroup]\n",
    "    \n",
    "    \n",
    "    listGroup = [(x[0],x[2],x[3],1) if datetime.datetime.fromtimestamp(int(x[1])).hour >= 6 and\n",
    "                datetime.datetime.fromtimestamp(int(x[1])).hour <= 13\n",
    "                    else(\n",
    "                      (x[0],x[2],x[3],2) if datetime.datetime.fromtimestamp(int(x[1])).hour >= 13 and\n",
    "                        datetime.datetime.fromtimestamp(int(x[1])).hour <= 18\n",
    "                      else (x[0],x[2],x[3],3)\n",
    "                    )\n",
    "                for x in listGroup]\n",
    "    \n",
    "#     context for last app used\n",
    "#     newListGroup = []\n",
    "#     for i in range(len(listGroup)):\n",
    "#         if i == 0:\n",
    "#             newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],-1))\n",
    "#         else:\n",
    "#             newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],listGroup[i-1][0]))\n",
    "#    label with 1 and 0    \n",
    "#     newListGroup = []\n",
    "#     for i in range(len(listGroup)):\n",
    "#         NumberOfLastApp = 50\n",
    "#         if i < NumberOfLastApp:\n",
    "#             lastApp = [x[0] for x in listGroup[:i]]\n",
    "#             if listGroup[i][0] not in lastApp:\n",
    "#                 newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],0))\n",
    "#             else:\n",
    "#                 newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],1))\n",
    "#         else:\n",
    "#             lastApp = [x[0] for x in listGroup[i-NumberOfLastApp:i]]\n",
    "#             if listGroup[i][0] not in lastApp:\n",
    "#                 newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],0))\n",
    "#             else:\n",
    "#                 newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],1))\n",
    "#     listGroup = newListGroup   \n",
    "    #least recently used\n",
    "    l = len(listGroup) \n",
    "    numTrain = l * 8 / 10\n",
    "    numTest = l - numTrain\n",
    "    trainList = listGroup[:numTrain]      #0.8 train set\n",
    "    trainList = sorted(trainList,key=lambda x:int(x[1]), reverse=True);  #sort by timestamp with descending\n",
    "    RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "    Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "    NumberOfLastApp = 6\n",
    "    if len(Recommender) >= NumberOfLastApp:\n",
    "        lastApp = Recommender[:NumberOfLastApp]\n",
    "    else:    \n",
    "        lastApp = Recommender\n",
    "    newListGroup = []\n",
    "    for i in range(len(listGroup)):\n",
    "        if listGroup[i][0] not in lastApp:\n",
    "            newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],0))\n",
    "        else:\n",
    "            newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],1))\n",
    "    listGroup = newListGroup  \n",
    "    #listGroup = [(x[0],x[1],x[2],x[3],1) for x in listGroup]\n",
    "#     context for frequency\n",
    "#     newListGroup = []\n",
    "#     for i in range(len(listGroup)):\n",
    "#         if i == 0:\n",
    "#             newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],-1))\n",
    "#         else:\n",
    "#             appGourp = [x[0] for x in listGroup[:i]]\n",
    "#             frquentApp = Counter(appGourp).most_common()[0][0]\n",
    "#             newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],frquentApp))\n",
    "#    label with 1 and 0  \n",
    "#     newListGroup = []\n",
    "#     for i in range(len(listGroup)):\n",
    "#         if i == 0:\n",
    "#             newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],listGroup[i][4],0))\n",
    "#         else:\n",
    "#             appGourp = [x[0] for x in listGroup[:i]]\n",
    "#             frquentApp = Counter(appGourp).most_common()\n",
    "#             frquentApp = [x[0] for x in frquentApp]\n",
    "#             numberOfFrequentApp = 4\n",
    "#             if len(frquentApp) >= numberOfFrequentApp:\n",
    "#                 frquentApp = frquentApp[:numberOfFrequentApp]                \n",
    "#             if listGroup[i][0] not in frquentApp :\n",
    "#                 newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],listGroup[i][4],1))\n",
    "#             else:       \n",
    "#                 newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],listGroup[i][4],0))\n",
    "    #most recently used\n",
    "    l = len(listGroup) \n",
    "    numTrain = l * 8 / 10\n",
    "    numTest = l - numTrain\n",
    "    trainList = listGroup[:numTrain]      #0.8 train set\n",
    "    RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "    Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "    numberOfFrequentApp = 6\n",
    "    if len(Recommender) >= numberOfFrequentApp:\n",
    "        firstApp = Recommender[:numberOfFrequentApp]\n",
    "    else:\n",
    "        firstApp = Recommender\n",
    "    newListGroup = []\n",
    "    for i in range(len(listGroup)):\n",
    "        if listGroup[i][0] not in firstApp:\n",
    "            newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],listGroup[i][4],0))\n",
    "        else:\n",
    "            newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],listGroup[i][4],1))\n",
    "    listGroup = newListGroup \n",
    "    \n",
    "    #most frequently used\n",
    "    l = len(listGroup) \n",
    "    numTrain = l * 8 / 10\n",
    "    numTest = l - numTrain\n",
    "    trainList = listGroup[:numTrain]      #0.9 train set\n",
    "    RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "    Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "    Recommender =  [t[0] for t in Recommender] \n",
    "    \n",
    "    numberOfFrequentApp = 6\n",
    "    if len(Recommender) >= numberOfFrequentApp:\n",
    "        frequentApp = Recommender[:numberOfFrequentApp]\n",
    "    else:\n",
    "        frequentApp = Recommender\n",
    "    newListGroup = []\n",
    "    for i in range(len(listGroup)):\n",
    "        if listGroup[i][0] not in frequentApp:\n",
    "            newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],listGroup[i][4],listGroup[i][5],0))\n",
    "        else:\n",
    "            newListGroup.append((listGroup[i][0],listGroup[i][1],listGroup[i][2],listGroup[i][3],listGroup[i][4],listGroup[i][5],1))\n",
    "    listGroup = newListGroup \n",
    "\n",
    "    \n",
    "    #time = datetime.datetime.fromtimestamp(int(line[1][0][1]))\n",
    "    #line[1][1] = datetime.datetime.fromtimestamp(int(\"1284101485\")).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    #return line[0],(workGroup+homeGroup)[:20],listGroup[:20]#,len(workGroup+homeGroup),len(workGroup),len(homeGroup)\n",
    "    return line[0],newListGroup\n",
    "final = groupData.map(convertLocation)\n",
    "final.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def topFiveSortedList(oldList, context, probability):\n",
    "    for x in range(0,len(oldList)-1):\n",
    "        if x == 0 and oldList[x][1] < probability:\n",
    "            oldList[x] = (context,probability)\n",
    "            if oldList[x+1][1] < oldList[x][1]:\n",
    "                temp = oldList[x+1] \n",
    "                oldList[x+1] = oldList[x]\n",
    "                oldList[x] = temp \n",
    "            else:\n",
    "                break\n",
    "        elif oldList[x+1][1] < oldList[x][1]:\n",
    "            temp = oldList[x+1] \n",
    "            oldList[x+1] = oldList[x]\n",
    "            oldList[x] = temp \n",
    "        else:\n",
    "            break\n",
    "    #return sorted(oldList,key=lambda x: -x[1])\n",
    "    return oldList      \n",
    "\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "\n",
    "def bayesian(line):\n",
    "    listGroup = line[1]\n",
    "    #shuffle(listGroup)                  #shuffle the list\n",
    "    l = len(listGroup) \n",
    "    numTrain = l * 8 / 10\n",
    "    numTest = l - numTrain\n",
    "    trainList = listGroup[:numTrain]      #0.8 train set\n",
    "    testList = listGroup[numTrain:]       #0.2 test set\n",
    "    \n",
    "    #trainRDD = sc.parallelize(trainList).count()\n",
    "    newTestList = []\n",
    "    for t in testList:\n",
    "        context = [x for x in trainList if x[1]==t[1] and x[2]==t[2] and x[3]==t[3] and x[4]==t[4] and x[5]==t[5] and x[6]==t[6]]\n",
    "        #context = [x for x in trainList if x[1]==t[1] and x[3]==t[3]]\n",
    "        numContext = float(len(context))\n",
    "        if numTrain != 0:\n",
    "            p_context = numContext/numTrain  #P(C1i, C2j, C3k)\n",
    "        else:\n",
    "            p_context = 0\n",
    "        p_app = [(-1,0),(-1,0),(-1,0),(-1,0),(-1,0)]\n",
    "        context_no_duplicate = remove_duplicates(context)\n",
    "        for c in context_no_duplicate:\n",
    "            appi = [x for x in trainList if x[0]==c[0]]\n",
    "            numAppi = float(len(appi))\n",
    "            if numTrain != 0:\n",
    "                p_appi = numAppi/numTrain\n",
    "            else:\n",
    "                p_appi = 0\n",
    "            contextAppi = [x for x in trainList if x[0]==c[0] and x[1]==c[1] and x[2]==c[2] and x[3]==c[3] and x[4]==c[4] and x[5]==c[5] and x[6]==c[6]]\n",
    "            #contextAppi = [x for x in trainList if x[0]==c[0] and x[1]==c[1] and x[3]==c[3]]\n",
    "            if numAppi != 0:    #P(C1i, C2j, C3k | APPid)\n",
    "                p_contextAppi = len(contextAppi)/numAppi \n",
    "            else:\n",
    "                p_contextAppi = 0\n",
    "            if p_context != 0:  #P(APPid | C1i,C2j,C3k = P(C1i, C2j, C3k | APPid)  P(APPid) /P(C1i, C2j, C3k)\n",
    "                p = p_contextAppi * p_appi / p_context\n",
    "            else:\n",
    "                p = 0\n",
    "            p_app = topFiveSortedList(p_app,c[0],p)\n",
    "        p_app = sorted(p_app,key=lambda x: -x[1])\n",
    "        app_rec = map(lambda x:x[0],p_app[:5])\n",
    "        newTestList.append((t[0],app_rec))\n",
    "    scores = 0\n",
    "    numHit = 0\n",
    "\n",
    "    for t in newTestList:\n",
    "        if t[0] == t[1][0]:\n",
    "            scores = scores+1.0\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][1]:\n",
    "            scores = scores+0.8\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][2]:\n",
    "            scores = scores+0.6\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][3]:\n",
    "            scores = scores+0.4\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][4]:\n",
    "            scores = scores+0.2\n",
    "            numHit = numHit+1\n",
    "        else:\n",
    "            numHit = numHit+1\n",
    "    #scores = scores / numTest\n",
    "    if numHit != 0:\n",
    "        scores = scores / numHit\n",
    "    else:\n",
    "        scores = 0\n",
    "    #return newTestList[:20]\n",
    "    return scores\n",
    "result = final.map(bayesian)\n",
    "#result.mean()\n",
    "f = open('asdf2.txt','a')\n",
    "f.write(str(result.mean()) + ' last 6 app, first top 6, frequency 6 added according to whole train data with all data')\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def topFiveSortedList(oldList, context, probability):\n",
    "    for x in range(0,len(oldList)-1):\n",
    "        if x == 0 and oldList[x][1] < probability:\n",
    "            oldList[x] = (context,probability)\n",
    "            if oldList[x+1][1] < oldList[x][1]:\n",
    "                temp = oldList[x+1] \n",
    "                oldList[x+1] = oldList[x]\n",
    "                oldList[x] = temp \n",
    "            else:\n",
    "                break\n",
    "        elif oldList[x+1][1] < oldList[x][1]:\n",
    "            temp = oldList[x+1] \n",
    "            oldList[x+1] = oldList[x]\n",
    "            oldList[x] = temp \n",
    "        else:\n",
    "            break\n",
    "    #return sorted(oldList,key=lambda x: -x[1])\n",
    "    return oldList      \n",
    "\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "\n",
    "def bayesian(line):\n",
    "    listGroup = line[1]\n",
    "    #shuffle(listGroup)                  #shuffle the list\n",
    "    l = len(listGroup) \n",
    "    numTrain = l * 8 / 10\n",
    "    numTest = l - numTrain\n",
    "    trainList = listGroup[:numTrain]      #0.8 train set\n",
    "    testList = listGroup[numTrain:]       #0.2 test set\n",
    "    \n",
    "    #trainRDD = sc.parallelize(trainList).count()\n",
    "    newTestList = []\n",
    "    for t in testList:\n",
    "        context = [x for x in trainList if x[1]==t[1] and x[2]==t[2] and x[3]==t[3] and x[4]==t[4] and x[5]==t[5] and x[6]==t[6]]\n",
    "        #context = [x for x in trainList if x[1]==t[1] and x[3]==t[3]]\n",
    "        numContext = float(len(context))\n",
    "        if numTrain != 0:\n",
    "            p_context = numContext/numTrain  #P(C1i, C2j, C3k)\n",
    "        else:\n",
    "            p_context = 0\n",
    "        p_app = [(-1,0),(-1,0),(-1,0),(-1,0),(-1,0)]\n",
    "        context_no_duplicate = remove_duplicates(context)\n",
    "        for c in context_no_duplicate:\n",
    "            appi = [x for x in trainList if x[0]==c[0]]\n",
    "            numAppi = float(len(appi))\n",
    "            if numTrain != 0:\n",
    "                p_appi = numAppi/numTrain\n",
    "            else:\n",
    "                p_appi = 0\n",
    "            contextAppi = [x for x in trainList if x[0]==c[0] and x[1]==c[1] and x[2]==c[2] and x[3]==c[3] and x[4]==c[4] and x[5]==c[5] and x[6]==c[6]]\n",
    "            #contextAppi = [x for x in trainList if x[0]==c[0] and x[1]==c[1] and x[3]==c[3]]\n",
    "            if numAppi != 0:    #P(C1i, C2j, C3k | APPid)\n",
    "                p_contextAppi = len(contextAppi)/numAppi \n",
    "            else:\n",
    "                p_contextAppi = 0\n",
    "            if p_context != 0:  #P(APPid | C1i,C2j,C3k = P(C1i, C2j, C3k | APPid)  P(APPid) /P(C1i, C2j, C3k)\n",
    "                p = p_contextAppi * p_appi / p_context\n",
    "            else:\n",
    "                p = 0\n",
    "            p_app = topFiveSortedList(p_app,c[0],p)\n",
    "        p_app = sorted(p_app,key=lambda x: -x[1])\n",
    "        app_rec = map(lambda x:x[0],p_app[:5])\n",
    "        newTestList.append((t[0],app_rec))\n",
    "    scores = 0\n",
    "    numHit = 0\n",
    "\n",
    "    for t in newTestList:\n",
    "        if t[0] == t[1][0]:\n",
    "            scores = scores+1.0\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][1]:\n",
    "            scores = scores+0.8\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][2]:\n",
    "            scores = scores+0.6\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][3]:\n",
    "            scores = scores+0.4\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][4]:\n",
    "            scores = scores+0.2\n",
    "            numHit = numHit+1\n",
    "#         else:\n",
    "#             numHit = numHit+1\n",
    "    #scores = scores / numTest\n",
    "    if numHit != 0:\n",
    "        scores = scores / numHit\n",
    "    else:\n",
    "        scores = 0\n",
    "    #return newTestList[:20]\n",
    "    return scores\n",
    "result = final.map(bayesian)\n",
    "#result.mean()\n",
    "f = open('asdf2.txt','a')\n",
    "f.write(str(result.mean()) + ' last 6 app, first top 6, frequency 6 added according to whole train data with all data with quality hits')\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def topFiveSortedList(oldList, context, probability):\n",
    "    for x in range(0,len(oldList)-1):\n",
    "        if x == 0 and oldList[x][1] < probability:\n",
    "            oldList[x] = (context,probability)\n",
    "            if oldList[x+1][1] < oldList[x][1]:\n",
    "                temp = oldList[x+1] \n",
    "                oldList[x+1] = oldList[x]\n",
    "                oldList[x] = temp \n",
    "            else:\n",
    "                break\n",
    "        elif oldList[x+1][1] < oldList[x][1]:\n",
    "            temp = oldList[x+1] \n",
    "            oldList[x+1] = oldList[x]\n",
    "            oldList[x] = temp \n",
    "        else:\n",
    "            break\n",
    "    #return sorted(oldList,key=lambda x: -x[1])\n",
    "    return oldList      \n",
    "\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "\n",
    "def bayesian(line):\n",
    "    listGroup = line[1]\n",
    "    #shuffle(listGroup)                  #shuffle the list\n",
    "    l = len(listGroup) \n",
    "    numTrain = l * 8 / 10\n",
    "    numTest = l - numTrain\n",
    "    trainList = listGroup[:numTrain]      #0.8 train set\n",
    "    testList = listGroup[numTrain:]       #0.2 test set\n",
    "    \n",
    "    #trainRDD = sc.parallelize(trainList).count()\n",
    "    newTestList = []\n",
    "    for t in testList:\n",
    "        context = [x for x in trainList if x[1]==t[1] and x[2]==t[2] and x[3]==t[3] and x[4]==t[4] and x[5]==t[5] and x[6]==t[6]]\n",
    "        #context = [x for x in trainList if x[1]==t[1] and x[3]==t[3]]\n",
    "        numContext = float(len(context))\n",
    "        if numTrain != 0:\n",
    "            p_context = numContext/numTrain  #P(C1i, C2j, C3k)\n",
    "        else:\n",
    "            p_context = 0\n",
    "        p_app = [(-1,0),(-1,0),(-1,0),(-1,0),(-1,0)]\n",
    "        context_no_duplicate = remove_duplicates(context)\n",
    "        for c in context_no_duplicate:\n",
    "            appi = [x for x in trainList if x[0]==c[0]]\n",
    "            numAppi = float(len(appi))\n",
    "            if numTrain != 0:\n",
    "                p_appi = numAppi/numTrain\n",
    "            else:\n",
    "                p_appi = 0\n",
    "            contextAppi = [x for x in trainList if x[0]==c[0] and x[1]==c[1] and x[2]==c[2] and x[3]==c[3] and x[4]==c[4] and x[5]==c[5] and x[6]==c[6]]\n",
    "            #contextAppi = [x for x in trainList if x[0]==c[0] and x[1]==c[1] and x[3]==c[3]]\n",
    "            if numAppi != 0:    #P(C1i, C2j, C3k | APPid)\n",
    "                p_contextAppi = len(contextAppi)/numAppi \n",
    "            else:\n",
    "                p_contextAppi = 0\n",
    "            if p_context != 0:  #P(APPid | C1i,C2j,C3k = P(C1i, C2j, C3k | APPid)  P(APPid) /P(C1i, C2j, C3k)\n",
    "                p = p_contextAppi * p_appi / p_context\n",
    "            else:\n",
    "                p = 0\n",
    "            p_app = topFiveSortedList(p_app,c[0],p)\n",
    "        p_app = sorted(p_app,key=lambda x: -x[1])\n",
    "        app_rec = map(lambda x:x[0],p_app[:5])\n",
    "        newTestList.append((t[0],app_rec))\n",
    "    scores = 0\n",
    "    numHit = 0\n",
    "\n",
    "    for t in newTestList:\n",
    "        if t[0] == t[1][0]:\n",
    "            scores = scores+1.0\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][1]:\n",
    "            scores = scores+0.8\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][2]:\n",
    "            scores = scores+0.6\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][3]:\n",
    "            scores = scores+0.4\n",
    "            numHit = numHit+1\n",
    "        elif t[0] == t[1][4]:\n",
    "            scores = scores+0.2\n",
    "            numHit = numHit+1\n",
    "#         else:\n",
    "#             numHit = numHit+1\n",
    "    #scores = scores / numTest\n",
    "    if numHit != 0:\n",
    "        scores = scores / numHit\n",
    "    else:\n",
    "        scores = 0\n",
    "    #return newTestList[:20]\n",
    "    return scores\n",
    "result = final.map(bayesian)\n",
    "#result.mean()\n",
    "f = open('asdf2.txt','a')\n",
    "f.write(str(result.mean()) + ' last 6 app, first top 6, frequency 6 added according to whole train data with all data for hit rate')\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "a = ((1,1),(1,2),(2,3))\n",
    "b = [x[0] for x in a]\n",
    "count = Counter(b).most_common()\n",
    "count = [x[0] for x in count]\n",
    "1 not in count\n",
    "\n",
    "listGroup = [1,1,1,1,1,1]\n",
    "for i in range(len(listGroup)):\n",
    "    print listGroup[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
