{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f3921b8a5d4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msplitedRdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitedRdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparseContextData2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#splitedRdd = sc.parallelize(splitedRdd.take(10000))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msplitedRddSample1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplitedRdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtakeSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0msplitedRddSample2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplitedRdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtakeSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msplitedRddSample1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mert/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtakeSample\u001b[1;34m(self, withReplacement, num, seed)\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[0minitialCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitialCount\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mert/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m         \"\"\"\n\u001b[1;32m--> 984\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mert/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36msum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;36m6.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \"\"\"\n\u001b[1;32m--> 975\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mert/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mfold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m    850\u001b[0m                 \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mert/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \"\"\"\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mert/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m    538\u001b[0m                 self.target_id, self.name)\n",
      "\u001b[1;32m/home/mert/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_give_back_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mert/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[1;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    432\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(\"../script/utils.py\")\n",
    "eventsPath = os.environ[\"YAHOO_DATA\"]\n",
    "splitedRdd = sc.textFile(eventsPath + \"/splitedData\")\n",
    "splitedRdd = splitedRdd.map(parseContextData2)\n",
    "#splitedRdd = sc.parallelize(splitedRdd.take(10000))\n",
    "splitedRddSample1 = sc.parallelize(splitedRdd.takeSample(True, 2000,0))\n",
    "splitedRddSample2 = sc.parallelize(splitedRdd.takeSample(True, 2000,1))\n",
    "splitedRddSample1.take(1)\n",
    "#(uid,[[train],[test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRecList = 5\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "def topFiveSortedList(oldList, context, probability):\n",
    "    context_oldList = [x[0] for x in oldList]\n",
    "    if context not in context_oldList:\n",
    "        for x in range(0,len(oldList)-1):\n",
    "            if x == 0 and oldList[x][1] < probability:\n",
    "                oldList[x] = (context,probability)\n",
    "                if oldList[x+1][1] < oldList[x][1]:\n",
    "                    temp = oldList[x+1] \n",
    "                    oldList[x+1] = oldList[x]\n",
    "                    oldList[x] = temp \n",
    "                else:\n",
    "                    break\n",
    "            elif oldList[x+1][1] < oldList[x][1]:\n",
    "                temp = oldList[x+1] \n",
    "                oldList[x+1] = oldList[x]\n",
    "                oldList[x] = temp \n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        index = context_oldList.index(context)\n",
    "        if oldList[index][1] < probability:\n",
    "            oldList[index] = (context,probability)\n",
    "        oldList = sorted(oldList,key=lambda x: x[1])\n",
    "    return oldList     \n",
    "def evaluation_rr(testList, recList):\n",
    "    scores = 0\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                scores = scores + 1.0 / (i+1)\n",
    "                break\n",
    "    if len(testList) != 0 :\n",
    "        scores = scores / len(testList)\n",
    "    return scores\n",
    "def evaluation_rr1(testItem, recList):\n",
    "    scores = 0\n",
    "    for i in range(len(recList)):\n",
    "        if testItem == recList[i]:\n",
    "            scores = 1.0 / (i+1)\n",
    "            break\n",
    "    return scores\n",
    "def evaluation_ap(testList, recList):\n",
    "    scores = 0\n",
    "    num = 0 \n",
    "    rr = []\n",
    "    rr[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                rr[i] = 1\n",
    "    \n",
    "    for t in testList:    \n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                for j in range(i,len(recList)):    \n",
    "                    if rr[j] == 1:\n",
    "                        scores = scores + 1.0 / (j+1)\n",
    "                        num = num + 1\n",
    "                break\n",
    "    if num == 0:\n",
    "        scores = 0\n",
    "    else:\n",
    "        scores = scores / num\n",
    "    return scores\n",
    "\n",
    "def evaluation_rap(testList,recList):\n",
    "    scores = 0.0\n",
    "    hitNum = 0  \n",
    "    for i in range(len(recList)):\n",
    "        if recList[i] in testList:\n",
    "            hitNum = hitNum + 1\n",
    "            scores = scores + 1.0*hitNum/(i+1)\n",
    "    if hitNum != 0:\n",
    "        scores = scores/hitNum\n",
    "    else:\n",
    "        scores = 0\n",
    "    return scores\n",
    "\n",
    "def evaluation_recall(testList, recList):\n",
    "    scores = 0\n",
    "    num = 0\n",
    "    recall = []\n",
    "    recall[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    rr=[]\n",
    "    rr[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                rr[i] = 1\n",
    "    for t in testList:    \n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                for j in range(i,len(recList)):    \n",
    "                    recall[j] = recall[j] + 1.0\n",
    "                    num = num + 1  \n",
    "                break    \n",
    "    recall = [0 if len(testList) == 0 else x/len(testList) for x in recall]\n",
    "    return recall\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "\n",
    "def evaluation_precision(testItem, recList):\n",
    "    scores = 0\n",
    "    if testItem in recList:\n",
    "        scores = 1.0\n",
    "    return scores  \n",
    "\n",
    "\n",
    "def print_result(finalScore, algorithm_name):\n",
    "    f = open('result/mfu_test_result3.txt','a')\n",
    "    f.write('2000 users with duplicated evaluations with installed data')\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr:'+str(finalScore.map(lambda x:x[0]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr1:'+str(finalScore.map(lambda x:x[1]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by map:'+str(finalScore.map(lambda x:x[2]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by recall:')\n",
    "    for i in range(numRecList):\n",
    "        if i == 0:\n",
    "            f.write(' '+str(finalScore.map(lambda x:x[3][i]).mean()))\n",
    "        elif i == numRecList-1:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[3][i]).mean()) + '\\n')\n",
    "        else:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[3][i]).mean()))\n",
    "            \n",
    "    f.write(algorithm_name + ' by precision:'+str(finalScore.map(lambda x:x[4]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by rap:'+str(finalScore.map(lambda x:x[5]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from collections import Counter\n",
    "f = open('result/mfu_test_result2.txt','a')\n",
    "f.write('-------normal mfu-----')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "def mfuFunction(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    \n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    trainList = listGroup[0]     #0.8 train set\n",
    "    testList = listGroup[1]    #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    \n",
    "    for i in range(numTest):  \n",
    "        testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "        Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "#        testcount = Counter(testList_items).most_common()\n",
    "        \n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]), reverse=True);  #sort by timestamp with descending\n",
    "        RecommenderDuplicate1 =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender1 = remove_duplicates(RecommenderDuplicate1)    #remove duplicate\n",
    "        Recommender = [[t[0],t[1]*5] if t[0] in Recommender1[:10] else t for t in Recommender]\n",
    "#         Recommender = [[t[0],1.0*t[1]/numTrain] for t in Recommender]\n",
    "#         testcount = [[t[0],1.0*t[1]/numTest] for t in testcount]\n",
    "       \n",
    "    #weighted\n",
    "#         Recommender =  [[t,0] for t in Recommender] \n",
    "#         for i in range(len(Recommender)):\n",
    "#             for j in range(len(trainList)):\n",
    "#                 if trainList[j][0] == Recommender[i][0]:\n",
    "#                     if len(trainList)>0 and (trainList[-1][1][0] - trainList[j][1][0]) == 0:\n",
    "#                         weight = 1\n",
    "#                     elif len(trainList)>0:\n",
    "#                         weight = (trainList[-1][1][0] - trainList[j][1][0])/86400\n",
    "#                     else:\n",
    "#                         weight = 0\n",
    "#                     if weight != 0:\n",
    "#                         Recommender[i][1] = Recommender[i][1] + 1.0/weight\n",
    "        Recommender = sorted(Recommender,key=lambda x:-x[1])\n",
    "        Recommender =  [t[0] for t in Recommender] \n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0])); ####\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_rr1 = scores_rr1 / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "\n",
    "finalScore = splitedRdd1.map(mfuFunction)\n",
    "print_result(finalScore,'mfu_sample1')\n",
    "finalScore = splitedRdd2.map(mfuFunction)\n",
    "print_result(finalScore,'mfu_sample2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from collections import Counter\n",
    "f = open('result/mfu_test_result2.txt','a')\n",
    "f.write('-------normal mfu-----')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "def mfuFunctionInstalled(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    \n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    trainList = listGroup[0]     #0.8 train set\n",
    "    testList = listGroup[1]    #0.2 test set\n",
    "    installedList = listGroup[2]\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    \n",
    "    for i in range(numTest):  \n",
    "        testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "        RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "        #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "        Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "#        testcount = Counter(testList_items).most_common()\n",
    "        \n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0]), reverse=True);  #sort by timestamp with descending\n",
    "        RecommenderDuplicate1 =  [t[0] for t in trainList]        #take only id for train set\n",
    "        Recommender1 = remove_duplicates(RecommenderDuplicate1)    #remove duplicate\n",
    "        Recommender = [[t[0],t[1]*5] if t[0] in Recommender1[:10] else t for t in Recommender]\n",
    "#         Recommender = [[t[0],1.0*t[1]/numTrain] for t in Recommender]\n",
    "#         testcount = [[t[0],1.0*t[1]/numTest] for t in testcount]\n",
    "       \n",
    "    #weighted\n",
    "#         Recommender =  [[t,0] for t in Recommender] \n",
    "#         for i in range(len(Recommender)):\n",
    "#             for j in range(len(trainList)):\n",
    "#                 if trainList[j][0] == Recommender[i][0]:\n",
    "#                     if len(trainList)>0 and (trainList[-1][1][0] - trainList[j][1][0]) == 0:\n",
    "#                         weight = 1\n",
    "#                     elif len(trainList)>0:\n",
    "#                         weight = (trainList[-1][1][0] - trainList[j][1][0])/86400\n",
    "#                     else:\n",
    "#                         weight = 0\n",
    "#                     if weight != 0:\n",
    "#                         Recommender[i][1] = Recommender[i][1] + 1.0/weight\n",
    "        Recommender = sorted(Recommender,key=lambda x:-x[1])\n",
    "        Recommender =  [t[0] for t in Recommender] \n",
    "        if len(Recommender) > 4:\n",
    "            finalRecommender = Recommender[:5]\n",
    "        else:\n",
    "            finalRecommender = [-1,-1,-1,-1,-1]\n",
    "            numRec = len(Recommender)\n",
    "            finalRecommender[:numRec] = Recommender\n",
    "        scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "        scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "        scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "        scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "        scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "        scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "        trainList = sorted(trainList,key=lambda x:int(x[1][0])); ####\n",
    "        trainList.append(testList[0])\n",
    "        testList.pop(0)  \n",
    "    if numTest != 0:\n",
    "        scores_rr = scores_rr / numTest\n",
    "        scores_rr1 = scores_rr1 / numTest\n",
    "        scores_ap = scores_ap / numTest\n",
    "        scores_recall = [x / numTest for x in scores_recall]\n",
    "        scores_precision = scores_precision / numTest\n",
    "        scores_rap = scores_rap / numTest\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "\n",
    "finalScore = splitedRdd1.map(mfuFunctionInstalled)\n",
    "print_result(finalScore,'mfu_sample1')\n",
    "finalScore = splitedRdd2.map(mfuFunctionInstalled)\n",
    "print_result(finalScore,'mfu_sample2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
