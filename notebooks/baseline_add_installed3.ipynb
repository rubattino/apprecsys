{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15490"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventsPath = os.environ[\"YAHOO_DATA\"]\n",
    "execfile(\"../script/utils.py\")\n",
    "splitedRddMerged = sc.textFile(eventsPath + \"splitedDataMerged\")\n",
    "splitedRddMergedParsed = splitedRddMerged.map(parseContextData2Merged)\n",
    "def filter_func(line,factor):\n",
    "    data = line[1]\n",
    "    if len(data[1]) == 0:\n",
    "        return False\n",
    "    return len(data[2])/float(len(data[1])) > factor\n",
    "splitedRddMergedParsed10p = splitedRddMergedParsed.filter(lambda x: filter_func(x,0.1))\n",
    "splitedRddMergedParsed10p.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRecList = 5\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "def topFiveSortedList(oldList, context, probability):\n",
    "    context_oldList = [x[0] for x in oldList]\n",
    "    if context not in context_oldList:\n",
    "        for x in range(0,len(oldList)-1):\n",
    "            if x == 0 and oldList[x][1] < probability:\n",
    "                oldList[x] = (context,probability)\n",
    "                if oldList[x+1][1] < oldList[x][1]:\n",
    "                    temp = oldList[x+1] \n",
    "                    oldList[x+1] = oldList[x]\n",
    "                    oldList[x] = temp \n",
    "                else:\n",
    "                    break\n",
    "            elif oldList[x+1][1] < oldList[x][1]:\n",
    "                temp = oldList[x+1] \n",
    "                oldList[x+1] = oldList[x]\n",
    "                oldList[x] = temp \n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        index = context_oldList.index(context)\n",
    "        if oldList[index][1] < probability:\n",
    "            oldList[index] = (context,probability)\n",
    "        oldList = sorted(oldList,key=lambda x: x[1])\n",
    "    return oldList     \n",
    "def evaluation_rr(testList, recList):\n",
    "    scores = 0\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                scores = scores + 1.0 / (i+1)\n",
    "                break\n",
    "    if len(testList) != 0 :\n",
    "        scores = scores / len(testList)\n",
    "    return scores\n",
    "def evaluation_rr1(testItem, recList):\n",
    "    scores = 0\n",
    "    for i in range(len(recList)):\n",
    "        if testItem == recList[i]:\n",
    "            scores = 1.0 / (i+1)\n",
    "            break\n",
    "    return scores\n",
    "def evaluation_ap(testList, recList):\n",
    "    scores = 0\n",
    "    num = 0 \n",
    "    rr = []\n",
    "    rr[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                rr[i] = 1\n",
    "    \n",
    "    for t in testList:    \n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                for j in range(i,len(recList)):    \n",
    "                    if rr[j] == 1:\n",
    "                        scores = scores + 1.0 / (j+1)\n",
    "                        num = num + 1\n",
    "                break\n",
    "    if num == 0:\n",
    "        scores = 0\n",
    "    else:\n",
    "        scores = scores / num\n",
    "    return scores\n",
    "\n",
    "def evaluation_rap(testList,recList):\n",
    "    scores = 0.0\n",
    "    hitNum = 0  \n",
    "    for i in range(len(recList)):\n",
    "        if recList[i] in testList:\n",
    "            hitNum = hitNum + 1\n",
    "            scores = scores + 1.0*hitNum/(i+1)\n",
    "    if hitNum != 0:\n",
    "        scores = scores/hitNum\n",
    "    else:\n",
    "        scores = 0\n",
    "    return scores\n",
    "\n",
    "def evaluation_recall(testList, recList):\n",
    "    scores = 0\n",
    "    num = 0\n",
    "    recall = []\n",
    "    recall[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    rr=[]\n",
    "    rr[:len(recList)] = [0 for i in range(len(recList))]\n",
    "    for t in testList:\n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                rr[i] = 1\n",
    "    for t in testList:    \n",
    "        for i in range(len(recList)):\n",
    "            if t == recList[i]:\n",
    "                for j in range(i,len(recList)):    \n",
    "                    recall[j] = recall[j] + 1.0\n",
    "                    num = num + 1  \n",
    "                break    \n",
    "    recall = [0 if len(testList) == 0 else x/len(testList) for x in recall]\n",
    "    return recall\n",
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output\n",
    "\n",
    "def evaluation_precision(testItem, recList):\n",
    "    scores = 0\n",
    "    if testItem in recList:\n",
    "        scores = 1.0\n",
    "    return scores  \n",
    "\n",
    "\n",
    "def print_result(finalScore, algorithm_name):\n",
    "    f = open('result/mfu_test_result5.txt','a')\n",
    "    f.write('10P type of users with only evaluation after installed')\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr:'+str(finalScore.map(lambda x:x[0]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by mrr1:'+str(finalScore.map(lambda x:x[1]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by map:'+str(finalScore.map(lambda x:x[2]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by recall:')\n",
    "    for i in range(numRecList):\n",
    "        if i == 0:\n",
    "            f.write(' '+str(finalScore.map(lambda x:x[3][i]).mean()))\n",
    "        elif i == numRecList-1:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[3][i]).mean()) + '\\n')\n",
    "        else:\n",
    "            f.write(','+str(finalScore.map(lambda x:x[3][i]).mean()))\n",
    "            \n",
    "    f.write(algorithm_name + ' by precision:'+str(finalScore.map(lambda x:x[4]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.write(algorithm_name + ' by rap:'+str(finalScore.map(lambda x:x[5]).mean()))\n",
    "    f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from collections import Counter\n",
    "f = open('result/mfu_test_result5.txt','a')\n",
    "f.write('-------normal mfu 10p 5 rounds after installed-----')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "def mfuFunction(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    \n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    trainList = listGroup[0]     #0.8 train set\n",
    "    testList = listGroup[1]    #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    \n",
    "    installedList = listGroup[2]\n",
    "    installedList = [t for t in installedList if t[1][0]>testList[0][1][0]]\n",
    "    numInstalled = len(installedList)\n",
    "    numEvaluation = 0\n",
    "    for j in range(numInstalled):  \n",
    "        testList = [t for t in listGroup[1] if t[1][0]>installedList[j][1][0]] #take only testitems after installed\n",
    "        testListRemoved = [t for t in listGroup[1] if t[1][0]<=installedList[j][1][0]] #take testitems before installed\n",
    "        trainList = listGroup[0] \n",
    "        trainList.extend(testListRemoved)\n",
    "        if len(testList)>5:\n",
    "            rounds = 5\n",
    "        else:\n",
    "            rounds = len(testList)\n",
    "        numEvaluation = numEvaluation + rounds\n",
    "        for i in range(rounds):\n",
    "            testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "            RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "            #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "            Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "            Recommender =  [t[0] for t in Recommender] \n",
    "            if len(Recommender) > 4:\n",
    "                finalRecommender = Recommender[:5]\n",
    "            else:\n",
    "                finalRecommender = [-1,-1,-1,-1,-1]\n",
    "                numRec = len(Recommender)\n",
    "                finalRecommender[:numRec] = Recommender\n",
    "            scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "            scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "            scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "            scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "            scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "            scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "            trainList.append(testList[0])\n",
    "            testList.pop(0)  \n",
    "        \n",
    "        \n",
    "    if numEvaluation != 0:\n",
    "        scores_rr = scores_rr / numEvaluation\n",
    "        scores_rr1 = scores_rr1 / numEvaluation\n",
    "        scores_ap = scores_ap / numEvaluation\n",
    "        scores_recall = [x / numEvaluation for x in scores_recall]\n",
    "        scores_precision = scores_precision / numEvaluation\n",
    "        scores_rap = scores_rap / numEvaluation\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "\n",
    "finalScore = splitedRddMergedParsed10p.map(mfuFunction)\n",
    "print_result(finalScore,'mfu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from collections import Counter\n",
    "f = open('result/mfu_test_result5.txt','a')\n",
    "f.write('-------installed mfu 10p 5 rounds after installed-----')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "def mfuFunctionInstalled(line):\n",
    "    listGroup = line[1]\n",
    "    l = len(listGroup)  \n",
    "    \n",
    "    scores_precision = 0.0\n",
    "    scores_rr = 0.0\n",
    "    scores_rr1 = 0.0\n",
    "    scores_ap = 0.0\n",
    "    scores_rap = 0.0\n",
    "    scores_recall = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    trainList = listGroup[0]     #0.8 train set\n",
    "    testList = listGroup[1]    #0.2 test set\n",
    "    numTrain = len(trainList)\n",
    "    numTest = len(testList)\n",
    "    \n",
    "    installedList = listGroup[2]\n",
    "    installedList = [t for t in installedList if t[1][0]>testList[0][1][0]]\n",
    "    numInstalled = len(installedList)\n",
    "    numEvaluation = 0\n",
    "    for j in range(numInstalled):  \n",
    "        testList = [t for t in listGroup[1] if t[1][0]>installedList[j][1][0]] #take only testitems after installed\n",
    "        testListRemoved = [t for t in listGroup[1] if t[1][0]<installedList[j][1][0]] #take testitems before installed\n",
    "        trainList = listGroup[0] \n",
    "        trainList.extend(testListRemoved)\n",
    "        if len(testList)>5:\n",
    "            rounds = 5\n",
    "        else:\n",
    "            rounds = len(testList)\n",
    "        numEvaluation = numEvaluation + rounds\n",
    "        for i in range(rounds):\n",
    "            testList_items = [t[0] for t in testList]                #take only id for test set\n",
    "            RecommenderDuplicate =  [t[0] for t in trainList]        #take only id for train set\n",
    "            #Recommender = remove_duplicates(RecommenderDuplicate)    #remove duplicate\n",
    "            Recommender = Counter(RecommenderDuplicate).most_common()\n",
    "            Recommender =  [t[0] for t in Recommender] \n",
    "            if len(Recommender) > 4:\n",
    "                finalRecommender = Recommender[:5]\n",
    "            else:\n",
    "                finalRecommender = [-1,-1,-1,-1,-1]\n",
    "                numRec = len(Recommender)\n",
    "                finalRecommender[:numRec] = Recommender\n",
    "\n",
    "            #added situation of installed------\n",
    "            if numTrain>5:\n",
    "                InstalledApps = [t[0] for t in installedList if t[1][0]<testList[0][1][0] and t[1][0]>trainList[-5][1][0]]\n",
    "            else:\n",
    "                InstalledApps = []\n",
    "            if len(InstalledApps)>0: # and index_inserted<5:\n",
    "                finalRecommender[0:0] = InstalledApps[:1]\n",
    "                finalRecommender = finalRecommender[:5]  \n",
    "                if testList[0][0] in InstalledApps[:1]  and testList[0][0] in finalRecommender:\n",
    "                    installedList = [t for t in installedList if t[0] != testList[0][0]]\n",
    "            #added situation of installed------   \n",
    "\n",
    "            scores_rr = evaluation_rr(testList_items, finalRecommender) + scores_rr\n",
    "            scores_rr1 = evaluation_rr1(testList[0][0], finalRecommender) + scores_rr1\n",
    "            scores_ap = evaluation_ap(testList_items, finalRecommender) + scores_ap\n",
    "            scores_recall = map(add, evaluation_recall(testList_items, finalRecommender), scores_recall)\n",
    "            scores_precision = evaluation_precision(testList[0][0], finalRecommender) + scores_precision\n",
    "            scores_rap = evaluation_rap(remove_duplicates(testList_items), finalRecommender) + scores_rap\n",
    "            trainList.append(testList[0])\n",
    "            testList.pop(0)  \n",
    "        \n",
    "    if numEvaluation != 0:\n",
    "        scores_rr = scores_rr / numEvaluation\n",
    "        scores_rr1 = scores_rr1 / numEvaluation\n",
    "        scores_ap = scores_ap / numEvaluation\n",
    "        scores_recall = [x / numEvaluation for x in scores_recall]\n",
    "        scores_precision = scores_precision / numEvaluation\n",
    "        scores_rap = scores_rap / numEvaluation\n",
    "    return scores_rr, scores_rr1, scores_ap, scores_recall, scores_precision, scores_rap\n",
    "#finalScore.take(1)\n",
    "finalScore = splitedRddMergedParsed10p.map(mfuFunctionInstalled)\n",
    "print_result(finalScore,'mfuFunctionInstalled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa =  [1,2,3,4,5,1]        #take only id for train set\n",
    "bb = remove_duplicates(aaa)    #remove duplicate\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
